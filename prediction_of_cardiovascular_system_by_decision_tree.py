# -*- coding: utf-8 -*-
"""PREDICTION_OF_CARDIOVASCULAR_SYSTEM_BY_DECISION_TREE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KeYJEkss1yu-RnDhJD36PBQXnC5JKw5f

# Importing Libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

"""# Loading Dataset"""

df = pd.read_csv("processed_cleveland.csv")
df.head()

df['num'].value_counts()

"""# Shape of the Data"""

df.shape

"""The dataset contains 303 Rows and 14 Columns

# Dataset Information
"""

df.info()

"""The dataset contains 1 float columns, 11 int columns & 2 object columns

# Columns in dataset
"""

df.columns

"""# Data Description"""

df.describe().T

# This shows the min, max, mean values, values at different quantiles, total number of non-null observations and 
# standard deviation for each variable.

df.describe(include='object').T

# This shows the total number of non-null observations, count of unique values, mode of values and its name.

"""# Null values"""

df.isnull().sum()

"""There are no null values in the above dataset

# Target Variable
"""

df['num'].value_counts()

"""Converting Target variable to binary class"""

df['num'] = np.where(df['num'] >1, 1, 0)

plt.figure(figsize=(15, 8)) 
plt.subplot(1,2,1)
df['num'].value_counts(normalize = True).plot(kind = 'bar', color = 'green')
plt.title('Num')
plt.subplot(1,2,2)
plt.title('Num')
df['num'].value_counts(normalize = True).plot(kind = 'pie', labels = df['num'], autopct='%1.1f%%', explode = [0, 0.1])
plt.show()

df['num'].value_counts()

df.head()

plt.figure(figsize=(15, 8)) 
sns.distplot(df['trestbps'])
plt.title('Trestbps')
plt.show()

df['trestbps'].skew()

""". From the above plot we can observe that trestbps is normally distributed
. In most most of the cases we can observe trestbps is in range of 100 - 160
"""

plt.figure(figsize=(15, 8)) 
sns.distplot(df['chol'])
plt.title('Chol')
plt.show()

df['chol'].skew()

""". From the above plot we can that chol is right skewed.
. Most of the times we can observe chol is in range of 100 - 400
"""

plt.figure(figsize=(15, 8)) 
sns.distplot(df['thalach'])
plt.title('Thalach')
plt.show()

df['thalach'].skew()

""". From the above plot we can that thalach is normally distributed 
. Most of the times we can observe thalach is in range of 100 - 200
"""

plt.figure(figsize=(15, 8)) 
sns.distplot(df['oldpeak'])
plt.title('Oldpeak')
plt.show()

""". From the above plot we can that oldpeak is right skewed. 
. Most of the times we can observe oldpeak is in range of 100 - 200
"""

plt.figure(figsize=(15, 8)) 
sns.countplot(df['sex'])
plt.title('SEX')
plt.show()

""". 1 represents male, 0 represents female"""

plt.figure(figsize=(15, 8)) 
sns.countplot(df['cp'])
plt.title('Chest Pain')
plt.show()

plt.figure(figsize=(15, 8)) 
sns.countplot(df['fbs'])
plt.title('Fasting Blood Sugar')
plt.show()

plt.figure(figsize=(15, 8)) 
sns.countplot(df['slope'])
plt.title('Slope')
plt.show()

plt.figure(figsize=(15, 8)) 
sns.scatterplot(df['trestbps'], df['chol'], hue = df['num'])
plt.show()

plt.figure(figsize=(15,8))
sns.heatmap(df.corr(), annot = True, linewidth = 0.5, cmap='summer')
plt.show()

plt.figure(figsize=(15,8))
df.boxplot()
plt.show()

for i in df.select_dtypes(include=['int','float64']):
    print('Variable name:', i)
    sns.boxplot(df[i])
    plt.show()

"""# Normalizing the data"""

df[df['thal'] == '?']

df[df['ca'] == '?']

"""Dropping The Rows having special Characters ("?")"""

df = df[~((df['ca']=="?")|(df['thal']=="?"))].astype(int)

df['ca'].value_counts()

df['thal'].value_counts()

df.shape

df.head()

from sklearn.preprocessing import MinMaxScaler
mm = MinMaxScaler()
df_norm = mm.fit_transform(df)

df_norm = pd.DataFrame(df_norm, columns=df.columns)

df_norm.head()

"""# Considering Target Variable"""

y = df_norm['num']
x = df_norm.drop('num', axis = 1)

y.value_counts()

x.head()

"""# Train Test Split"""

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=20)
print('The shape of the x_train:',x_train.shape)
print('The shape of the x_test:',x_test.shape)
print('The shape of the y_train:',y_train.shape)
print('The shape of the y_test:',y_test.shape)





"""# Logistic Regression"""

from sklearn.linear_model import LogisticRegression
lr = LogisticRegression(solver='saga')
df_lr = lr.fit(x_train, y_train)
df_lr_pred_test = df_lr.predict(x_test)
df_lr_pred_train = df_lr.predict(x_train)
df_lr_prob = df_lr.predict_proba(x_test)[:,1]

from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
lr_acc_score_test = print('The test accuracy score of Logistic Regression is: ', accuracy_score(y_test,df_lr_pred_test)*100)
lr_acc_score_test

from sklearn.metrics import accuracy_score
lr_acc_score_train = print('The train accuracy score of Logistic Regression is: ', accuracy_score(y_train,df_lr_pred_train)*100)
lr_acc_score_train

from sklearn.metrics import roc_auc_score
print('The roc_auc_score for logistic regression is :', roc_auc_score(y_test, df_lr_prob)*100)

print('The f1 score of Logistic Regression is: ', f1_score(y_test,df_lr_pred_test)*100)
print('The Precision score of Logistic Regression is: ', precision_score(y_test,df_lr_pred_test)*100)
print('The Recall score of Logistic Regression is: ', recall_score(y_test,df_lr_pred_test)*100)

from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix

print('Classification report : \n',classification_report(y_test,df_lr_pred_test))
print('confusion matrix : \n',confusion_matrix(y_test,df_lr_pred_test))
sns.heatmap(confusion_matrix(y_test,df_lr_pred_test), annot = True)
plt.show()

"""# Random Forest"""

from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier()
df_rfc = rfc.fit(x_train, y_train)
df_rfc_pred_test = df_rfc.predict(x_test)
df_rfc_pred_train = df_rfc.predict(x_train)
df_rfc_prob = df_rfc.predict_proba(x_test)[:,1]

rfc_acc_score_test = print('The accuracy score of Random Forest is: ', accuracy_score(y_test,df_rfc_pred_test)*100)
rfc_acc_score_test

rfc_acc_score_train = print('The accuracy score of Random Forest is: ', accuracy_score(y_train,df_rfc_pred_train)*100)
rfc_acc_score_train

print('The roc_auc_score for Random Forest is :', roc_auc_score(y_test, df_rfc_prob)*100)

print('The f1 score of Random Forest is: ', f1_score(y_test,df_rfc_pred_test)*100)
print('The Precision score of Random Forest is: ', precision_score(y_test,df_rfc_pred_test)*100)
print('The Recall score of Random Forest is: ', recall_score(y_test,df_rfc_pred_test)*100)

print('Classification report : \n',classification_report(y_test,df_rfc_pred_test))
print('confusion matrix : \n',confusion_matrix(y_test,df_rfc_pred_test))
sns.heatmap(confusion_matrix(y_test,df_rfc_pred_test), annot = True)
plt.show()

"""# KNearest Neighbouring"""

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(metric='euclidean')
df_knn = knn.fit(x_train, y_train)
df_knn_pred_test = df_knn.predict(x_test)
df_knn_pred_train = df_knn.predict(x_train)
df_knn_prob = df_knn.predict_proba(x_test)[:,1]

knn_acc_score_test = print('The accuracy test score of Knn is: ', accuracy_score(y_test,df_knn_pred_test)*100)
knn_acc_score_test

knn_acc_score_train = print('The accuracy train score of Knn is: ', accuracy_score(y_train,df_knn_pred_train)*100)
knn_acc_score_train

print('The roc_auc_score for Knn is :', roc_auc_score(y_test, df_knn_prob)*100)

print('The f1 score of Knn is: ', f1_score(y_test,df_knn_pred_test)*100)
print('The Precision score of Knn is: ', precision_score(y_test,df_knn_pred_test)*100)
print('The Recall score of Knn is: ', recall_score(y_test,df_knn_pred_test)*100)

print('Classification report : \n',classification_report(y_test,df_knn_pred_test))
print('confusion matrix : \n',confusion_matrix(y_test,df_knn_pred_test))
sns.heatmap(confusion_matrix(y_test,df_knn_pred_test), annot = True)
plt.show()

"""# Naive Bayes"""

from sklearn.naive_bayes import GaussianNB
nb = GaussianNB()
df_nb = nb.fit(x_train, y_train)
df_nb_pred_test = df_nb.predict(x_test)
df_nb_pred_train = df_nb.predict(x_train)
df_nb_prob = df_nb.predict_proba(x_test)[:,1]

nb_acc_score = print('The accuracy test score of Naive Bayes is: ', accuracy_score(y_test,df_nb_pred_test)*100)
nb_acc_score

nb_acc_score = print('The accuracy train score of Naive Bayes is: ', accuracy_score(y_train,df_nb_pred_train)*100)
nb_acc_score

print('The roc_auc_score for Naive Bayes is :', roc_auc_score(y_test, df_nb_prob)*100)

print('The f1 score of Naive Bayes is: ', f1_score(y_test,df_nb_pred_test)*100)
print('The Precision score of Naive Bayes is: ', precision_score(y_test,df_nb_pred_test)*100)
print('The Recall score of Naive Bayes is: ', recall_score(y_test,df_nb_pred_test)*100)

print('Classification report : \n',classification_report(y_test,df_nb_pred_test))
print('confusion matrix : \n',confusion_matrix(y_test,df_nb_pred_test))
sns.heatmap(confusion_matrix(y_test,df_nb_pred_test), annot = True)
plt.show()

"""# XG Boost Classifier"""

from xgboost import XGBClassifier

from xgboost import XGBClassifier
xgb = XGBClassifier()
df_xgb = xgb.fit(x_train, y_train)
df_xgb_pred_test = df_xgb.predict(x_test)
df_xgb_pred_train = df_xgb.predict(x_train)
df_xgb_prob = df_xgb.predict_proba(x_test)[:,1]

xgb_acc_score = print('The accuracy score of XGB is: ', accuracy_score(y_test,df_xgb_pred_test)*100)
xgb_acc_score

xgb_acc_score = print('The accuracy score of XGB is: ', accuracy_score(y_train,df_xgb_pred_train)*100)
xgb_acc_score

print('The roc_auc_score for XGB is :', roc_auc_score(y_test, df_xgb_prob)*100)

print('The f1 score of XGB is: ', f1_score(y_test,df_xgb_pred_test)*100)
print('The Precision score of XGB is: ', precision_score(y_test,df_xgb_pred_test)*100)
print('The Recall score of XGB is: ', recall_score(y_test,df_xgb_pred_test)*100)

print('Classification report : \n',classification_report(y_test,df_xgb_pred_test))
print('confusion matrix : \n',confusion_matrix(y_test,df_xgb_pred_test))
sns.heatmap(confusion_matrix(y_test,df_xgb_pred_test), annot = True)
plt.show()

"""# Decision Tree"""

from sklearn.tree import DecisionTreeClassifier
dtc = DecisionTreeClassifier()
df_dtc = dtc.fit(x_train, y_train)
df_dtc_pred_test = df_dtc.predict(x_test)
df_dtc_pred_train = df_dtc.predict(x_train)
df_dtc_prob = df_dtc.predict_proba(x_test)[:,1]

dtc_acc_score = print('The accuracy score of Decision Tree is: ', accuracy_score(y_test,df_dtc_pred_test)*100)
dtc_acc_score

dtc_acc_score = print('The accuracy score of Decision Tree is: ', accuracy_score(y_train,df_dtc_pred_train)*100)
dtc_acc_score

print('The roc_auc_score for Decision Tree is :', roc_auc_score(y_test, df_dtc_prob)*100)

print('The f1 score of Decision Tree is: ', f1_score(y_test,df_dtc_pred_test)*100)
print('The Precision score of Decision Tree is: ', precision_score(y_test,df_dtc_pred_test)*100)
print('The Recall score of Decision Tree is: ', recall_score(y_test,df_dtc_pred_test)*100)

print('Classification report : \n',classification_report(y_test,df_dtc_pred_test))
print('confusion matrix : \n',confusion_matrix(y_test,df_dtc_pred_test))
sns.heatmap(confusion_matrix(y_test,df_dtc_pred_test), annot = True)
plt.show()

from sklearn import tree
plt.figure(figsize=(15,10))
tree.plot_tree(df_dtc, filled = True)

!pip3 install chefboost

"""# ID3 Algorithm"""

from chefboost import Chefboost as chef

x_train_df, x_test_df = train_test_split(df_norm, test_size=0.2, stratify=df_norm['num'])

config = {'algorithm': 'ID3', 'enableParallelism': True, 'num_cores' : 2}
model = chef.fit(x_train_df, target_label= 'num', config = config)

pred = chef.predict(model, x_test_df.iloc[0])
#evalu = chef.evaluate(model, x_test_df, task = 'num')

"""# C4.5 Algorithm"""

config = {'algorithm': 'C4.5', 'enableParallelism': False}
model = chef.fit(df_norm, target_label= 'num', config = config)

"""# CART Algorithm"""

config = {'algorithm': 'CART', 'enableParallelism': False}
model = chef.fit(df_norm, target_label= 'num', config = config)

"""# Pre Pruning"""

from sklearn.model_selection import GridSearchCV

grid_params = {'criterion':['gini','entropy','log_loss'],
              'splitter':['best', 'random'],
              'max_depth':[1,3,5,7],
              'min_samples_leaf':[1,3,5,7],
              'min_samples_split':[1,3,5,7]}

gs = GridSearchCV(estimator=dtc, param_grid=grid_params, cv=5)
gs.fit(x_train, y_train)

print(gs.best_params_)

dtc_pre = DecisionTreeClassifier(criterion= 'entropy', max_depth= 7, min_samples_leaf= 3, 
                                 min_samples_split= 5, splitter= 'best')
dtc_pre.fit(x_train, y_train)

dtc_pre_pred1_test = dtc_pre.predict(x_test)
dtc_pre_pred1_train = dtc_pre.predict(x_train)
dtc_pre_prob1 = dtc_pre.predict_proba(x_test)[:,1]

dtc_pred1_acc_score = print('The test accuracy score of Decision Tree Pre pruning 1 is: ', accuracy_score(y_test,dtc_pre_pred1_test)*100)
dtc_pred1_acc_score

dtc_pred1_acc_score = print('The train accuracy score of Decision Tree Pre pruning 1 is: ', accuracy_score(y_train,dtc_pre_pred1_train)*100)
dtc_pred1_acc_score

print('The roc_auc_score for Decision Tree Pre Pruning 1 is :', roc_auc_score(y_test, dtc_pre_prob1)*100)

print('The f1 score of Decision Tree preprune 1 is: ', f1_score(y_test,dtc_pre_pred1_test)*100)
print('The Precision score of Decision Tree preprune 1 is: ', precision_score(y_test,dtc_pre_pred1_test)*100)
print('The Recall score of Decision Tree preprune 1 is: ', recall_score(y_test,dtc_pre_pred1_test)*100)

print('Classification report : \n',classification_report(y_test,dtc_pre_pred1_test))
print('confusion matrix : \n',confusion_matrix(y_test,dtc_pre_pred1_test))
sns.heatmap(confusion_matrix(y_test,dtc_pre_pred1_test), annot = True)
plt.show()

from sklearn import tree
plt.figure(figsize=(15,10))
tree.plot_tree(dtc_pre, filled = True)

grid_params = {'criterion':['gini','entropy','log_loss'],
              'splitter':['best', 'random'],
              'max_depth':[2,4,6,8],
              'min_samples_leaf':[2,4,6,8],
              'min_samples_split':[2,4,6,8]}

gs = GridSearchCV(estimator=dtc, param_grid=grid_params, cv=5)
gs.fit(x_train, y_train)

print(gs.best_params_)

dtc_pre2 = DecisionTreeClassifier(criterion = 'gini', max_depth = 2, min_samples_leaf = 8, 
                                 min_samples_split = 8, splitter = 'random')
dtc_pre2.fit(x_train, y_train)

dtc_pre_pred2_test = dtc_pre2.predict(x_test)
dtc_pred2_acc_score = print('The Test accuracy score of Decision Tree Pre Pruning 2 is: ', accuracy_score(y_test,dtc_pre_pred2_test)*100)
dtc_pred2_acc_score

dtc_pre_pred2_train = dtc_pre2.predict(x_train)
dtc_pred2_acc_score = print('The Train accuracy score of Decision Tree Pre Pruning 2 is: ', accuracy_score(y_train,dtc_pre_pred2_train)*100)
dtc_pred2_acc_score

dtc_pre_prob2 = dtc_pre2.predict_proba(x_test)[:,1]
print('The roc_auc_score for Decision Tree Pre Pruning 2 is :', roc_auc_score(y_test, dtc_pre_prob2)*100)

print('The f1 score of Decision Tree preprune 2 is: ', f1_score(y_test,dtc_pre_pred2_test)*100)
print('The Precision score of Decision Tree preprune 2 is: ', precision_score(y_test,dtc_pre_pred2_test)*100)
print('The Recall score of Decision Tree preprune 2 is: ', recall_score(y_test,dtc_pre_pred2_test)*100)

print('Classification report : \n',classification_report(y_test,dtc_pre_pred2_test))
print('confusion matrix : \n',confusion_matrix(y_test,dtc_pre_pred2_test))
sns.heatmap(confusion_matrix(y_test,dtc_pre_pred2_test), annot = True)
plt.show()

from sklearn import tree
plt.figure(figsize=(15,10))
tree.plot_tree(dtc_pre2, filled = True)

"""# Post Pruning"""

from sklearn.tree import DecisionTreeClassifier
dtc = DecisionTreeClassifier()
pru = dtc.cost_complexity_pruning_path(x_train, y_train)
ccp_alphas, impurities = pru.ccp_alphas, pru.impurities

ccp_alphas

impurities

dtcs = []
for i in ccp_alphas:
    dtc = DecisionTreeClassifier(random_state=0, ccp_alpha=i)
    dtc.fit(x_train, y_train)
    dtcs.append(dtc)
print('Number of nodes in the last tree is: {} with ccp_alpha: {}'.format(
    dtcs[-1].tree_.node_count, ccp_alphas[-1]))

plt.figure(figsize=(15,8))
train_scores = [i.score(x_train, y_train) for i in dtcs]
test_scores = [i.score(x_test, y_test) for i in dtcs]

ax = plt.subplot()
ax.set_xlabel('alpha values')
ax.set_ylabel('accuracy score')
ax.set_title('Accuracy vs Alpha')
ax.plot(ccp_alphas, train_scores, marker = 'o', label = 'train', drawstyle = 'steps-post')
ax.plot(ccp_alphas, test_scores, marker = 'o', label = 'test', drawstyle = 'steps-post')

ax.legend()
plt.show()

dtc_pru = DecisionTreeClassifier(random_state=0, ccp_alpha= 0.03)
dtc_pru.fit(x_train, y_train)

dtc_pru_pred_test = dtc_pru.predict(x_test)
dtc_pru_acc_score = print('The Test accuracy score of Decision Tree Post Pruning is: ', accuracy_score(y_test,dtc_pru_pred_test)*100)
dtc_pru_acc_score

dtc_pru_pred_train = dtc_pru.predict(x_train)
dtc_pru_acc_score = print('The Train accuracy score of Decision Tree Post Pruning is: ', accuracy_score(y_train,dtc_pru_pred_train)*100)
dtc_pru_acc_score

dtc_pru_prob = dtc_pru.predict_proba(x_test)[:,1]
print('The roc_auc_score for Decision Tree Post Pruning is :', roc_auc_score(y_test, dtc_pru_prob)*100)

print('The f1 score of Decision Tree post prune is: ', f1_score(y_test,dtc_pru_pred_test)*100)
print('The Precision score of Decision Tree post prune is: ', precision_score(y_test,dtc_pru_pred_test)*100)
print('The Recall score of Decision Tree post prune is: ', recall_score(y_test,dtc_pru_pred_test)*100)

print('Classification report : \n',classification_report(y_test,dtc_pru_pred_test))
print('confusion matrix : \n',confusion_matrix(y_test,dtc_pru_pred_test))
sns.heatmap(confusion_matrix(y_test,dtc_pru_pred_test), annot = True)
plt.show()

from sklearn import tree
plt.figure(figsize=(15,10))
tree.plot_tree(dtc_pru, filled = True)

"""# Voting Classifier"""

from sklearn.ensemble import VotingClassifier

lr = LogisticRegression(solver= 'sag')
rfc = RandomForestClassifier(criterion = 'entropy', max_depth = 8, min_samples_leaf = 6, 
                                 min_samples_split = 8)
knn = KNeighborsClassifier(n_neighbors= 8, weights='distance',algorithm='ball_tree', metric= 'euclidean')
nb = GaussianNB()
xgb = XGBClassifier()

estimator1 =  ('clf2', nb), ('clf3', lr), ('clf4', rfc), ('clf5', knn), ('clf6', xgb), ('clf7', dtc_pre)

vc= VotingClassifier(estimator1, voting='hard')
vc.fit(x_train, y_train)

vc_pred_test = vc.predict(x_test)

vc_acc_score = print('The accuracy score of voting classifier hard is: ', accuracy_score(y_test,vc_pred_test)*100)
vc_acc_score

vc_pred_train = vc.predict(x_train)
vc_acc_score = print('The accuracy score of voting classifier hard is: ', accuracy_score(y_train,vc_pred_train)*100)
vc_acc_score

print('The f1 score of Voting Classifier hard is: ', f1_score(y_test,vc_pred_test)*100)
print('The Precision score of Voting Classifier hard is: ', precision_score(y_test,vc_pred_test)*100)
print('The Recall score of Voting Classifier hard is: ', recall_score(y_test, vc_pred_test)*100)

print('Classification report : \n',classification_report(y_test,vc_pred_test))
print('confusion matrix : \n',confusion_matrix(y_test,vc_pred_test))
sns.heatmap(confusion_matrix(y_test,vc_pred_test), annot = True)
plt.show()

Results = pd.DataFrame({'Model': ['Logistic Regression', 'Random Forest', 'Knn', 'Naive Bayes', 'XGB','Decision Tree Base Model', 'Decision Tree pre prune 1', 'Decision Tree pre prune 2', 'Decision Tree post prune', 'Weight Voting Classifier'], 
              'Test_Accuracy':[83, 77, 80, 82,77,73,73,77,75,87],
             'Train Accuracy':[87, 100, 89, 86, 100, 100, 92, 82, 83, 90],
             'Roc_Auc_Score':[88, 90, 83, 82, 87, 69, 72, 79,71, ''],
             'F1 Score':[74, 59, 68, 74, 59, 58, 60, 59, 59, 75],
             'Precision Score':[74, 67, 68, 67, 67, 58, 57, 67, 61, 71],
             'Recall Score':[74, 53, 68, 84, 53, 58, 63, 53, 58, 79]})

Results

plt.figure(figsize=(20, 6))
splot=sns.barplot(x="Model",y="Test_Accuracy",data=Results)
for p in splot.patches:
    splot.annotate(format(p.get_height(), '.1f'), 
                   (p.get_x() + p.get_width() / 2., p.get_height()), 
                   ha = 'center', va = 'center', 
                   xytext = (0, 9), 
                   textcoords = 'offset points')
plt.xlabel("Models", size=14)
plt.ylabel("Test_Accuracy", size=14)
plt.title('Accuracy_Scores')
plt.show()









"""# PRINCIPAL COMPONANT ANALYSIS"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

df1 = pd.read_csv("processed_cleveland.csv")
df1.head()

df1['num'] = np.where(df1['num'] >1, 1, 0)

df1 = df1[~((df1['ca']=="?")|(df1['thal']=="?"))].astype(int)

df1.shape

from sklearn.preprocessing import MinMaxScaler
mm = MinMaxScaler()
df1_norm = mm.fit_transform(df1)

df1_norm = pd.DataFrame(df1_norm, columns=df1.columns)

from sklearn.decomposition import PCA

"""Converting 14 features into 2 features by PCA method"""

pca = PCA(n_components=2)

df1_pca = pca.fit_transform(df1_norm)

df1.shape

df1_pca.shape

df2 = pd.DataFrame(data = df1_pca, columns= ['PCA_1', 'PCA_2'])

df_final = pd.concat([df2, df1[['num']]], axis = 1)

df_final.head()

df_final.isnull().sum()

df_final.isnull().sum().sum()

per_null = df_final.isnull().sum() / df_final.shape[0] * 100
per_null

df_final = df_final.dropna(axis=0)

df_final.info()

plt.figure(figsize=(15,6))
sns.scatterplot(x = df_final['PCA_1'], y = df_final['PCA_2'], hue = df_final['num'])
plt.show()

"""# Train Test Split for PCA"""

y = df_final['num']
x = df_final.drop('num', axis = 1)

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=20)
print('The shape of the x_train:',x_train.shape)
print('The shape of the x_test:',x_test.shape)
print('The shape of the y_train:',y_train.shape)
print('The shape of the y_test:',y_test.shape)

"""# Logistic Regression"""

from sklearn.linear_model import LogisticRegression
lr_pca = LogisticRegression()
df_lr_pca = lr_pca.fit(x_train, y_train)
df_lr_pca_pred_test = df_lr_pca.predict(x_test)
df_lr_pca_pred_train = df_lr_pca.predict(x_train)
df_lr_pca_prob = df_lr_pca.predict_proba(x_test)[:,1]

from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
lr_acc_score_test = print('The test accuracy score of Logistic Regression is: ', accuracy_score(y_test,df_lr_pca_pred_test)*100)
lr_acc_score_test

from sklearn.metrics import accuracy_score
lr_acc_score_train = print('The train accuracy score of Logistic Regression is: ', accuracy_score(y_train,df_lr_pca_pred_train)*100)
lr_acc_score_train

from sklearn.metrics import roc_auc_score
print('The roc_auc_score for logistic regression is :', roc_auc_score(y_test, df_lr_pca_prob)*100)
print('The f1 score of Logistic Regression is: ', f1_score(y_test,df_lr_pca_pred_test)*100)
print('The Precision score of Logistic Regression is: ', precision_score(y_test,df_lr_pca_pred_test)*100)
print('The Recall score of Logistic Regression is: ', recall_score(y_test,df_lr_pca_pred_test)*100)

from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix

print('Classification report : \n',classification_report(y_test,df_lr_pca_pred_test))
print('confusion matrix : \n',confusion_matrix(y_test,df_lr_pca_pred_test))
sns.heatmap(confusion_matrix(y_test,df_lr_pca_pred_test), annot = True)
plt.show()

"""# Random Forest"""

from sklearn.ensemble import RandomForestClassifier
rfc_pca = RandomForestClassifier()
df_rfc_pca = rfc_pca.fit(x_train, y_train)
df_rfc_pca_pred_test = df_rfc_pca.predict(x_test)
df_rfc_pca_pred_train = df_rfc_pca.predict(x_train)
df_rfc_pca_prob = df_rfc_pca.predict_proba(x_test)[:,1]

rfc_acc_score_test = print('The accuracy score of Random Forest is: ', accuracy_score(y_test,df_rfc_pca_pred_test)*100)
rfc_acc_score_test

rfc_acc_score_train = print('The accuracy score of Random Forest is: ', accuracy_score(y_train,df_rfc_pca_pred_train)*100)
rfc_acc_score_train

print('The roc_auc_score for Random Forest is :', roc_auc_score(y_test, df_rfc_pca_prob)*100)

print('The f1 score of Random Forest is: ', f1_score(y_test,df_rfc_pca_pred_test)*100)
print('The Precision score of Random Forest is: ', precision_score(y_test,df_rfc_pca_pred_test)*100)
print('The Recall score of Random Forest is: ', recall_score(y_test,df_rfc_pca_pred_test)*100)

print('Classification report : \n',classification_report(y_test,df_rfc_pca_pred_test))
print('confusion matrix : \n',confusion_matrix(y_test,df_rfc_pca_pred_test))
sns.heatmap(confusion_matrix(y_test,df_rfc_pca_pred_test), annot = True)
plt.show()

"""# KNN"""

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier()
df_knn_pca = knn.fit(x_train, y_train)
df_knn_pca_pred_test = df_knn_pca.predict(x_test)
df_knn_pca_pred_train = df_knn_pca.predict(x_train)
df_knn_pca_prob = df_knn_pca.predict_proba(x_test)[:,1]

knn_acc_score_test = print('The accuracy test score of Knn is: ', accuracy_score(y_test,df_knn_pca_pred_test)*100)
knn_acc_score_test

knn_acc_score_train = print('The accuracy train score of Knn is: ', accuracy_score(y_train,df_knn_pca_pred_train)*100)
knn_acc_score_train

print('The roc_auc_score for Knn is :', roc_auc_score(y_test, df_knn_pca_prob)*100)

print('The f1 score of Knn is: ', f1_score(y_test,df_knn_pca_pred_test)*100)
print('The Precision score of Knn is: ', precision_score(y_test,df_knn_pca_pred_test)*100)
print('The Recall score of Knn is: ', recall_score(y_test,df_knn_pca_pred_test)*100)

print('Classification report : \n',classification_report(y_test,df_knn_pca_pred_test))
print('confusion matrix : \n',confusion_matrix(y_test,df_knn_pca_pred_test))
sns.heatmap(confusion_matrix(y_test,df_knn_pca_pred_test), annot = True)
plt.show()

"""# Naive Bayes"""

from sklearn.naive_bayes import GaussianNB
nb = GaussianNB()
df_nb_pca = nb.fit(x_train, y_train)
df_nb_pca_pred_test = df_nb_pca.predict(x_test)
df_nb_pca_pred_train = df_nb_pca.predict(x_train)
df_nb_pca_prob = df_nb_pca.predict_proba(x_test)[:,1]

nb_acc_score = print('The accuracy test score of Naive Bayes is: ', accuracy_score(y_test,df_nb_pca_pred_test)*100)
nb_acc_score

nb_acc_score = print('The accuracy train score of Naive Bayes is: ', accuracy_score(y_train,df_nb_pca_pred_train)*100)
nb_acc_score

print('The roc_auc_score for Naive Bayes is :', roc_auc_score(y_test, df_nb_pca_prob)*100)

print('The f1 score of Naive Bayes is: ', f1_score(y_test,df_nb_pca_pred_test)*100)
print('The Precision score of Naive Bayes is: ', precision_score(y_test,df_nb_pca_pred_test)*100)
print('The Recall score of Naive Bayes is: ', recall_score(y_test,df_nb_pca_pred_test)*100)

print('Classification report : \n',classification_report(y_test,df_nb_pca_pred_test))
print('confusion matrix : \n',confusion_matrix(y_test,df_nb_pca_pred_test))
sns.heatmap(confusion_matrix(y_test,df_nb_pca_pred_test), annot = True)
plt.show()

"""# Decision Tree"""

from sklearn.tree import DecisionTreeClassifier
dtc = DecisionTreeClassifier()
df_dtc_pca = dtc.fit(x_train, y_train)
df_dtc_pca_pred_test = df_dtc_pca.predict(x_test)
df_dtc_pca_pred_train = df_dtc_pca.predict(x_train)
df_dtc_pca_prob = df_dtc_pca.predict_proba(x_test)[:,1]

dtc_acc_score = print('The accuracy score of Decision Tree is: ', accuracy_score(y_test,df_dtc_pca_pred_test)*100)
dtc_acc_score

dtc_acc_score = print('The accuracy score of Decision Tree is: ', accuracy_score(y_train,df_dtc_pca_pred_train)*100)
dtc_acc_score

print('The roc_auc_score for Decision Tree is :', roc_auc_score(y_test, df_dtc_pca_prob)*100)

print('The f1 score of Decision Tree is: ', f1_score(y_test,df_dtc_pca_pred_test)*100)
print('The Precision score of Decision Tree is: ', precision_score(y_test,df_dtc_pca_pred_test)*100)
print('The Recall score of Decision Tree is: ', recall_score(y_test,df_dtc_pca_pred_test)*100)

print('Classification report : \n',classification_report(y_test,df_dtc_pca_pred_test))
print('confusion matrix : \n',confusion_matrix(y_test,df_dtc_pca_pred_test))
sns.heatmap(confusion_matrix(y_test,df_dtc_pca_pred_test), annot = True)
plt.show()

pd.DataFrame({'Model': ['Logistic Regression', 'Random Forest', 'Knn', 'Naive Bayes','Decision Tree Base Model'], 
              'Test_Accuracy':[72.88, 69.49, 66.10, 72.88, 71.1],
             'Train Accuracy':[72.10, 100, 76.82, 72.10, 100],
             'Roc_Auc_Score':[67, 68.45, 59.88, 67.44, 60.61],
             'F1 Score':[0, 30.76, 9.09, 0, 41.3],
             'Precision Score':[0, 40, 16.66, 0, 46.15],
             'Recall Score':[0, 25, 6.25, 0, 37.5]})

